##Below the script to fulfill the requirements of Coursera course #3,week #4 Project assignment
##Fistful you need to unzip the archive into your work dirctory by fillow the link.
##  https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
##The archive contains the number of useless data for that particular case. So below you can find the file names related to the case only.
##Archive downloaded 14th of May 2017 and the script was made basedon its structure. In case of further updates of source data, some parts of the script could not be work properly.
traindata_subj <- read.table("UCI HAR Dataset/train/subject_train.txt", header = FALSE) ##Reading data sets 9tests and trainings) for further manipulations
traindata_X <- read.table("UCI HAR Dataset/train/X_train.txt", header = FALSE)
traindata_y <- read.table("UCI HAR Dataset/train/y_train.txt", header = FALSE)
testdata_subj <- read.table("UCI HAR Dataset/test/subject_test.txt", header = FALSE)
testdata_X <- read.table("UCI HAR Dataset/test/X_test.txt", header = FALSE)
testdata_y <- read.table("UCI HAR Dataset/test/y_test.txt", header = FALSE)
varnames <- read.table("UCI HAR Dataset/features.txt", header = FALSE)
merged_subj <- rbind(testdata_subj, traindata_subj) ; names(merged_subj) <- c("subject") ##Merging the data by following the variables order(subject,
merged_y <- rbind(testdata_y, traindata_y)   ; names(merged_y) <- c("activity")          ## activity, main data contain 561 var list). So it is 563 columns in total
merged_X <- rbind(testdata_X, traindata_X)   ; names(merged_X) <- varnames$V2
merged_total<- cbind(merged_subj, merged_y, merged_X)
##Let's clean up the desk before going further.
rm(merged_X);rm(merged_y); rm(merged_subj); rm(testdata_X); rm(testdata_y); rm(testdata_subj); rm(traindata_X)
rm(traindata_y); rm(traindata_subj); rm(varnames)
##Leave the columns which contain mean and standard deviation amounts after activity and subject cells.
cleandata <- merged_total[,grep("[Aa]ctivity|[Ss]ubject|mean|std", colnames(merged_total))]
rm(merged_total) ##Let's clean up again, almost 9M is out from the laptop))
##Renaming of activity data by replacing the initial numeric values with the relaive names.
cleandata[, 2] <- read.table("UCI HAR Dataset/activity_labels.txt")[cleandata[,2],2]
names(cleandata[,2]) <- "Activity"
##Renaming the columns in order to make the table more clear for first time reader.
names(cleandata) <- make.names(names(cleandata))
names(cleandata) <- gsub('Acc',"Acceleration",names(cleandata))
names(cleandata) <- gsub('GyroJerk',"AngularAcceleration",names(cleandata))
names(cleandata) <- gsub('Gyro',"AngularSpeed",names(cleandata))
names(cleandata) <- gsub('Mag',"Magnitude",names(cleandata))
names(cleandata) <- gsub('^t',"TimeDomain.",names(cleandata))
names(cleandata) <- gsub('^f',"FrequencyDomain.",names(cleandata))
names(cleandata) <- gsub('\\.mean',".Mean",names(cleandata))
names(cleandata) <- gsub('\\.std',".StandardDeviation",names(cleandata))
names(cleandata) <- gsub('Freq\\.',"Frequency.",names(cleandata))
names(cleandata) <- gsub('Freq$',"Frequency",names(cleandata))
##Save the data into the file by using initial data format.
write.table(cleandata, './clean_merged_total.txt', row.names = FALSE)
##The independent data set contans the average of each variable for each activity and each subject. result is stored as .txt file accordingly.
ave_cleandata <- aggregate(x=cleandata, by=list(activities=cleandata$activity, subj=cleandata$subject), FUN=mean)
ave_cleandata <- ave_cleandata[, !(colnames(ave_cleandata) %in% c("subj", "activity"))]
write.table(ave_cleandata, './ave_cleandata.txt', row.names = FALSE)
##Assignment complete
##Below the script to fulfill the requirements of Coursera course #3,week #4 Project assignment
##Fistful you need to unzip the archive into your work dirctory by fillow the link.
##  https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
##The archive contains the number of useless data for that particular case. So below you can find the file names related to the case only.
##Archive downloaded 14th of May 2017 and the script was made basedon its structure. In case of further updates of source data, some parts of the script could not be work properly.
traindata_subj <- read.table("UCI HAR Dataset/train/subject_train.txt", header = FALSE) ##Reading data sets 9tests and trainings) for further manipulations
traindata_X <- read.table("UCI HAR Dataset/train/X_train.txt", header = FALSE)
traindata_y <- read.table("UCI HAR Dataset/train/y_train.txt", header = FALSE)
testdata_subj <- read.table("UCI HAR Dataset/test/subject_test.txt", header = FALSE)
testdata_X <- read.table("UCI HAR Dataset/test/X_test.txt", header = FALSE)
testdata_y <- read.table("UCI HAR Dataset/test/y_test.txt", header = FALSE)
varnames <- read.table("UCI HAR Dataset/features.txt", header = FALSE)
merged_subj <- rbind(testdata_subj, traindata_subj) ; names(merged_subj) <- c("subject") ##Merging the data by following the variables order(subject,
merged_y <- rbind(testdata_y, traindata_y)   ; names(merged_y) <- c("activity")          ## activity, main data contain 561 var list). So it is 563 columns in total
merged_X <- rbind(testdata_X, traindata_X)   ; names(merged_X) <- varnames$V2
merged_total<- cbind(merged_subj, merged_y, merged_X)
##Let's clean up the desk before going further.
rm(merged_X);rm(merged_y); rm(merged_subj); rm(testdata_X); rm(testdata_y); rm(testdata_subj); rm(traindata_X)
rm(traindata_y); rm(traindata_subj); rm(varnames)
##Leave the columns which contain mean and standard deviation amounts after activity and subject cells.
cleandata <- merged_total[,grep("[Aa]ctivity|[Ss]ubject|mean|std", colnames(merged_total))]
rm(merged_total) ##Let's clean up again, almost 9M is out from the laptop))
##Renaming of activity data by replacing the initial numeric values with the relaive names.
cleandata[, 2] <- read.table("UCI HAR Dataset/activity_labels.txt")[cleandata[,2],2]
names(cleandata[,2]) <- "Activity"
##Renaming the columns in order to make the table more clear for first time reader.
names(cleandata) <- make.names(names(cleandata))
names(cleandata) <- gsub('Acc',"Acceleration",names(cleandata))
names(cleandata) <- gsub('GyroJerk',"AngularAcceleration",names(cleandata))
names(cleandata) <- gsub('Gyro',"AngularSpeed",names(cleandata))
names(cleandata) <- gsub('Mag',"Magnitude",names(cleandata))
names(cleandata) <- gsub('^t',"TimeDomain.",names(cleandata))
names(cleandata) <- gsub('^f',"FrequencyDomain.",names(cleandata))
names(cleandata) <- gsub('\\.mean',".Mean",names(cleandata))
names(cleandata) <- gsub('\\.std',".StandardDeviation",names(cleandata))
names(cleandata) <- gsub('Freq\\.',"Frequency.",names(cleandata))
names(cleandata) <- gsub('Freq$',"Frequency",names(cleandata))
##Save the data into the file by using initial data format.
write.table(cleandata, './clean_merged_total.txt', row.names = FALSE)
##The independent data set contans the average of each variable for each activity and each subject. result is stored as .txt file accordingly.
ave_cleandata <- aggregate(x=cleandata, by=list(activities=cleandata$activity, subj=cleandata$subject), FUN=mean)
ave_cleandata <- ave_cleandata[, !(colnames(ave_cleandata) %in% c("subj", "activity"))]
write.table(ave_cleandata, './ave_cleandata.txt', row.names = FALSE)
##Assignment complete
example(points)
x <- rnorm(100)
y<-rnorm(100)
plot(x, y,pch =  20)
title("Scatterplot")
par(mar= c(2,2,2,2))
plot(x, y,pch =  20)
title("Scatterplot")
text(-2,-2, "label")
legend("topleft", legend = "Data", pch = 20)
fit <-  lm(y ~x)
abline(fit)
abline(fit, lwd = 3,col = "lightblue")
abline(fit, lwd = 3,col = "neonred")
abline(fit, lwd = 3,col = "magenta")
plot(x, y, xlab = )
plot(x, y, xlab = "Height", ylab = "Weight", main = "Scatterplot", pch= 20)
par(mar= c(5,3,4,2))
plot(x, y, xlab = "Height", ylab = "Weight", main = "Scatterplot", pch= 20)
par(mar)
par("mar")
x<- rnorm(100)
y<- x + rnorm(100)
g <- gl(2, 50, labels = c("Male", "Female"))
str(g)
str(g)
g
plot(x, y)
plot(x, y, type = "n")
points(x[g == "Male"], y[g == "Male"])
points(x[g == "Male"], y[g == "Male"], col = "green", pch = 20)
points(x[g == "Female"], y[g == "Feale"], col = "red", pch = 20)
points(x[g == "Female"], y[g == "Female"], col = "red", pch = 20)
plot(x, y, type = "n")
points(x[g == "Female"], y[g == "Feale"], col = "red")
points(x[g == "Female"], y[g == "Female"], col = "blue")
points(x[g == "Male"], y[g == "Male"], col = "green")
pdf(file = "myplot.pdf")
with(faithful, plot(eruptions, waiting))
title (main = "Old faithful Geyser data")
dev.off()
dev.cur()
?dev.cur
plot(x, y, type = "n")
points(x[g == "Female"], y[g == "Female"], col = "blue")
title (main = "Old faithful Geyser data")
dev.copy(png, file = "123.png")
dev.off()
library("swirl")
rm(list = ls())
swirl()
head(pollution)
dim(pollution)
summary(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm,col = "blue")
abline(h=12)
hist(ppm,col = "green")
rug(ppm)
low
high
hist(ppm, col= "green", breaks = 100)
rug(ppm)
hist(ppm,col="green")
abline(v=12,lwd = 2)
abline(v=median(ppm), col = "magenta",lwd = 4)
head(pollution)
names(pollution)
reg <- pollution$region
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main ="Number of Countriesin Each Region")
barplot(reg, col = "wheat", main ="Number of Counties in Each Region")
boxplot(pm25~region, pollution,col = "red")
par(mfrow=c(2,1), mar=c(4,4,2,1))
east<- subset(pollution,boolean, east)
east<- subset(pollution, boolean= "east")
east <- subset(pollution, region == "east")
head(east)
hist(east$pm25, col = "green")
west <- subset(pollution, region == "west")
hist(west$pm25, col = "green")
hist(subset(pollution,region=="west")$pm25, col = "green")
exit()
q()
swirl()
library("swirl")
swirl()
call(with(pollution,latitude,pm25))
with(call(pm25 ~ latitude, pollution))
with(call(pm25, latitude, pollution))
with(call(pm25, latitude, pollution))
skip()
abline(h=12, lwd=2, lty=2)
plot(pollution$latitude,ppm, col = pollution$region)
abline(h=12, lwd=2, lty=2)
par(mfrow=c(1,2), mar=c(5,4,2,1))
west <- subset(pollution, west)
west <- subset(pollution, region = west)
west <- subset(pollution, region = "west")
west <- subset(pollution, region == "west")
plot(west$latitude, west$pm25,main == "west")
plot(west$latitude, west$pm25, main == "west")
call(plot(west$latitude, west$pm25, main == "west"))
call(plot(west$latitude, west$pm25, main == "west"))
skip()
plot(east$latitude, east$pm25, main = "east")
plot(east$latitude, east$pm25, main = "East")
?Devices
windows(faithful, plot(eruptions, waiting))
skip()
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.cur()
pdf(file = "myplot.pdf")
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.cur()
dev.off()
dev.cur()
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser data")
dev.copy(png, file = "geyserplot.png")
dev.off()
q()
install.packages("ggplot2")
library("swirl")
swirl()
p1(6)
0xcc
p2 <- colorRampPalette(c("red","yellow"))
p2(2)
p2(10)
showMe(p1(20))
showMe(p2(20))
showMe(p2(2))
p1
?rgb
p3<- colorRampPalette(c("blue", 'green'), alpha = .5)
p3(5)
plot(x,y, pch= 19, col = rgb(0, .5, .5))
plot(x,y, pch= 19, col = rgb(0, .5, .5, .3))
brewer.pal(3, "BuGn")
cols <- brewer.pal(3, "BuGn")
showMe(cols)
pal <- colorRampPalette(cols)
showMe(pal(20))
image(volcano, col=pal(20))
image(volcano, col=p1(20))
library(ggplot2)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color =  drv)
qplot(displ, hwy, data = mpg, color =  drv, geom = c("point", "smooth"))
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(hwy, data = mpg, fill= drv)
rm(list=ls())
x<- rnorm(100)
y<-rnorm(100)
z<- rnorm(100)
a<-rpois(100)
a<-rpois(100,.5)
a<-rpois(100,3)
df <- data.frame(x, y, z, a)
dist(df)
hclust(df)
dist(df)
plot(dist(df))
dist(df)
df1<dist(df)
df1<-dist(df)
na.rm(df1) = TRUE
df1<-dist(df)
na.exclude(df1)
complete.cases(df1)
rm(list=ls())
hclust
variable.names(hclust)
variable.names(df)
args(hclust)
args(dist)
args(plot)
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip", activity_data)
setwd("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment")
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip", activity_data.zip)
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip", activity.zip)
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip",destfile = "activity.zip")
unzip("./activity.zip", overwrite=TRUE, junkpaths = FALSE)
unzip("./activity.zip", overwrite = TRUE, junkpaths = FALSE)
unzip("./activity.zip", overwrite = TRUE)
unzip("./activity.zip")
unzip("activity.zip")
unzip("./activity.zip")
setwd("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment")
unzip("./activity.zip", overwrite = TRUE, junkpaths = FALSE)
unzip("./activity.zip")
unzip("activity.zip")
unzip("C:\Users\atlen\Desktop\For Coursera courses\R Programming\Cousera5_week2_assignment\activity.zip")
unzip("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity.zip")
unzip("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity")
unzip("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity.zip")
unzip("C://Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity.zip")
unzip("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity.zip")
unzip("C:/Users/atlen/Desktop/For Coursera courses/R Programming/Cousera5_week2_assignment/activity")
dir()
unzip("activity.zip")
unzip(list = "activity.zip")
unzip("activity")
getwd()
dir()
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip",destfile = "activity.zip", "activity.zip")
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip",destfile = "activity.zip", dest.file= "activity.zip")
download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip",destfile = "activity.zip")
tempfile()<-download.file("https://github.com/atlen/RepData_PeerAssessment1/blob/master/activity.zip")
file(description = "activity")
q()
